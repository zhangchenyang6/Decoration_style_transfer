{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Use pretrained model vgg_16/vgg_16.ckpt\n",
      "INFO:tensorflow:Restoring parameters from vgg_16/vgg_16.ckpt\n",
      "INFO:tensorflow:Target style pattern is saved to: static/img/generated/target_style_beiou.jpg.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Loss network layers(You can define them in \"content_layers\" and \"style_layers\"):\n",
      "INFO:tensorflow:vgg_16/conv1/conv1_1\n",
      "INFO:tensorflow:vgg_16/conv1/conv1_2\n",
      "INFO:tensorflow:vgg_16/pool1\n",
      "INFO:tensorflow:vgg_16/conv2/conv2_1\n",
      "INFO:tensorflow:vgg_16/conv2/conv2_2\n",
      "INFO:tensorflow:vgg_16/pool2\n",
      "INFO:tensorflow:vgg_16/conv3/conv3_1\n",
      "INFO:tensorflow:vgg_16/conv3/conv3_2\n",
      "INFO:tensorflow:vgg_16/conv3/conv3_3\n",
      "INFO:tensorflow:vgg_16/pool3\n",
      "INFO:tensorflow:vgg_16/conv4/conv4_1\n",
      "INFO:tensorflow:vgg_16/conv4/conv4_2\n",
      "INFO:tensorflow:vgg_16/conv4/conv4_3\n",
      "INFO:tensorflow:vgg_16/pool4\n",
      "INFO:tensorflow:vgg_16/conv5/conv5_1\n",
      "INFO:tensorflow:vgg_16/conv5/conv5_2\n",
      "INFO:tensorflow:vgg_16/conv5/conv5_3\n",
      "INFO:tensorflow:vgg_16/pool5\n",
      "INFO:tensorflow:vgg_16/fc6\n",
      "INFO:tensorflow:vgg_16/fc7\n",
      "INFO:tensorflow:vgg_16/fc8\n",
      "INFO:tensorflow:Use pretrained model vgg_16/vgg_16.ckpt\n",
      "INFO:tensorflow:Restoring parameters from vgg_16/vgg_16.ckpt\n",
      "INFO:tensorflow:step: 10,  total Loss 527301.000000, secs/step: 15.112593,Tue Jun 11 10:12:16 2019\n",
      "INFO:tensorflow:step: 20,  total Loss 318868.781250, secs/step: 14.233095,Tue Jun 11 10:14:39 2019\n",
      "INFO:tensorflow:step: 30,  total Loss 393984.375000, secs/step: 14.259650,Tue Jun 11 10:17:02 2019\n",
      "INFO:tensorflow:step: 40,  total Loss 305897.906250, secs/step: 14.345915,Tue Jun 11 10:19:29 2019\n",
      "INFO:tensorflow:step: 50,  total Loss 428086.406250, secs/step: 14.239055,Tue Jun 11 10:21:53 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 60,  total Loss 374164.593750, secs/step: 14.337480,Tue Jun 11 10:24:18 2019\n",
      "INFO:tensorflow:step: 70,  total Loss 283403.968750, secs/step: 14.332786,Tue Jun 11 10:26:42 2019\n",
      "INFO:tensorflow:step: 80,  total Loss 355210.000000, secs/step: 13.973869,Tue Jun 11 10:29:06 2019\n",
      "INFO:tensorflow:step: 90,  total Loss 310543.406250, secs/step: 13.940497,Tue Jun 11 10:31:26 2019\n",
      "INFO:tensorflow:step: 100,  total Loss 418368.468750, secs/step: 13.943328,Tue Jun 11 10:33:47 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 110,  total Loss 342817.781250, secs/step: 14.053693,Tue Jun 11 10:36:07 2019\n",
      "INFO:tensorflow:step: 120,  total Loss 324711.937500, secs/step: 13.979057,Tue Jun 11 10:38:27 2019\n",
      "INFO:tensorflow:step: 130,  total Loss 294330.343750, secs/step: 13.966147,Tue Jun 11 10:40:47 2019\n",
      "INFO:tensorflow:step: 140,  total Loss 293011.406250, secs/step: 14.034301,Tue Jun 11 10:43:08 2019\n",
      "INFO:tensorflow:step: 150,  total Loss 337551.312500, secs/step: 13.978020,Tue Jun 11 10:45:28 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 160,  total Loss 359868.812500, secs/step: 13.999383,Tue Jun 11 10:47:48 2019\n",
      "INFO:tensorflow:step: 170,  total Loss 361756.687500, secs/step: 14.049865,Tue Jun 11 10:50:08 2019\n",
      "INFO:tensorflow:step: 180,  total Loss 396968.406250, secs/step: 14.077978,Tue Jun 11 10:52:30 2019\n",
      "INFO:tensorflow:step: 190,  total Loss 365199.718750, secs/step: 14.017312,Tue Jun 11 10:54:50 2019\n",
      "INFO:tensorflow:step: 200,  total Loss 333044.750000, secs/step: 14.059431,Tue Jun 11 10:57:11 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 210,  total Loss 391760.593750, secs/step: 13.945626,Tue Jun 11 10:59:30 2019\n",
      "INFO:tensorflow:step: 220,  total Loss 280921.843750, secs/step: 14.047733,Tue Jun 11 11:01:52 2019\n",
      "INFO:tensorflow:step: 230,  total Loss 289643.906250, secs/step: 13.939457,Tue Jun 11 11:04:12 2019\n",
      "INFO:tensorflow:step: 240,  total Loss 319798.968750, secs/step: 14.996524,Tue Jun 11 11:06:33 2019\n",
      "INFO:tensorflow:step: 250,  total Loss 317783.625000, secs/step: 13.919571,Tue Jun 11 11:08:52 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 260,  total Loss 305705.187500, secs/step: 13.898930,Tue Jun 11 11:11:12 2019\n",
      "INFO:tensorflow:step: 270,  total Loss 362723.531250, secs/step: 13.970377,Tue Jun 11 11:13:33 2019\n",
      "INFO:tensorflow:step: 280,  total Loss 301947.031250, secs/step: 13.832927,Tue Jun 11 11:15:53 2019\n",
      "INFO:tensorflow:step: 290,  total Loss 250863.937500, secs/step: 13.940437,Tue Jun 11 11:18:13 2019\n",
      "INFO:tensorflow:step: 300,  total Loss 347801.750000, secs/step: 15.993513,Tue Jun 11 11:20:35 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 310,  total Loss 315427.437500, secs/step: 13.869082,Tue Jun 11 11:22:55 2019\n",
      "INFO:tensorflow:step: 320,  total Loss 284026.343750, secs/step: 13.976320,Tue Jun 11 11:25:14 2019\n",
      "INFO:tensorflow:step: 330,  total Loss 309521.375000, secs/step: 13.995928,Tue Jun 11 11:27:35 2019\n",
      "INFO:tensorflow:step: 340,  total Loss 294795.281250, secs/step: 14.026999,Tue Jun 11 11:29:55 2019\n",
      "INFO:tensorflow:step: 350,  total Loss 315569.875000, secs/step: 13.873419,Tue Jun 11 11:32:17 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 360,  total Loss 253672.687500, secs/step: 13.907283,Tue Jun 11 11:34:37 2019\n",
      "INFO:tensorflow:step: 370,  total Loss 260206.281250, secs/step: 13.990892,Tue Jun 11 11:36:58 2019\n",
      "INFO:tensorflow:step: 380,  total Loss 307898.593750, secs/step: 13.999076,Tue Jun 11 11:39:18 2019\n",
      "INFO:tensorflow:step: 390,  total Loss 255229.781250, secs/step: 13.977163,Tue Jun 11 11:41:39 2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step: 400,  total Loss 205910.890625, secs/step: 13.916219,Tue Jun 11 11:43:59 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step: 410,  total Loss 227689.906250, secs/step: 14.166193,Tue Jun 11 11:46:20 2019\n",
      "INFO:tensorflow:step: 420,  total Loss 215042.968750, secs/step: 13.949824,Tue Jun 11 11:48:40 2019\n",
      "INFO:tensorflow:step: 430,  total Loss 247571.265625, secs/step: 13.925901,Tue Jun 11 11:51:00 2019\n",
      "INFO:tensorflow:step: 440,  total Loss 341681.281250, secs/step: 13.985369,Tue Jun 11 11:53:22 2019\n",
      "INFO:tensorflow:step: 450,  total Loss 289719.093750, secs/step: 13.920323,Tue Jun 11 11:55:42 2019\n",
      "INFO:tensorflow:saving check point...\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Done training -- epoch limit reached\n",
      "INFO:tensorflow:coordinator stop\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "from nets import nets_factory\n",
    "from preprocessing import preprocessing_factory\n",
    "import reader\n",
    "import model\n",
    "import time\n",
    "import losses\n",
    "import utils\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-c', '--conf', default='conf/beiou.yml', help='配置文件路径')\n",
    "    return parser.parse_args([])\n",
    "    \n",
    "\n",
    "def main(FLAGS):\n",
    "    style_features_t = losses.get_style_features(FLAGS)\n",
    "    training_path = os.path.join(FLAGS.model_path, FLAGS.naming)\n",
    "    if not (os.path.exists(training_path)):\n",
    "        os.makedirs(training_path)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            \"\"\"创建Network\"\"\"\n",
    "            network_fn = nets_factory.get_network_fn(\n",
    "                FLAGS.loss_model,\n",
    "                num_classes=1,\n",
    "                is_training=False)\n",
    "\n",
    "            image_preprocessing_fn, image_unprocessing_fn = preprocessing_factory.get_preprocessing(\n",
    "                FLAGS.loss_model,\n",
    "                is_training=False)\n",
    " \n",
    "            \"\"\"训练图片预处理\"\"\"\n",
    "            processed_images = reader.batch_image(FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size,\n",
    "                                                  'train2014/', image_preprocessing_fn, epochs=FLAGS.epoch)\n",
    "            generated = model.transform_network(processed_images, training=True)\n",
    "            processed_generated = [image_preprocessing_fn(image, FLAGS.image_size, FLAGS.image_size)\n",
    "                                   for image in tf.unstack(generated, axis=0, num=FLAGS.batch_size)\n",
    "                                   ]\n",
    "            processed_generated = tf.stack(processed_generated)\n",
    "            _, endpoints_dict = network_fn(tf.concat([processed_generated, processed_images], 0), spatial_squeeze=False)\n",
    "            tf.logging.info('Loss network layers(You can define them in \"content_layers\" and \"style_layers\"):')\n",
    "            for key in endpoints_dict:\n",
    "                tf.logging.info(key)\n",
    "\n",
    "            \"\"\"创建 Losses\"\"\"\n",
    "            content_loss = losses.content_loss(endpoints_dict, FLAGS.content_layers)\n",
    "            style_loss, style_loss_summary = losses.style_loss(endpoints_dict, style_features_t, FLAGS.style_layers)\n",
    "            tv_loss = losses.total_variation_loss(generated)  # use the unprocessed image\n",
    "\n",
    "            loss = FLAGS.style_weight * style_loss + FLAGS.content_weight * content_loss + FLAGS.tv_weight * tv_loss\n",
    "\n",
    "            \"\"\"准备训练\"\"\"\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            variable_to_train = []\n",
    "            for variable in tf.trainable_variables():\n",
    "                # 只训练和保存生成网络中的变量\n",
    "                if not (variable.name.startswith(FLAGS.loss_model)):\n",
    "                    variable_to_train.append(variable)\n",
    "\n",
    "            \"\"\"优化\"\"\"\n",
    "            train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step=global_step, var_list=variable_to_train)\n",
    "\n",
    "            variables_to_restore = []\n",
    "            for v in tf.global_variables():\n",
    "                if not (v.name.startswith(FLAGS.loss_model)):\n",
    "                    variables_to_restore.append(v)\n",
    "            saver = tf.train.Saver(variables_to_restore, write_version=tf.train.SaverDef.V1)\n",
    "            sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "            init_func = utils._get_init_fn(FLAGS)\n",
    "            init_func(sess)\n",
    "            last_file = tf.train.latest_checkpoint(training_path)\n",
    "            if last_file:\n",
    "                tf.logging.info('Restoring model from {}'.format(last_file))\n",
    "                saver.restore(sess, last_file)\n",
    "\n",
    "            \"\"\"开始训练\"\"\"\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while not coord.should_stop():\n",
    "                    _, loss_t, step = sess.run([train_op, loss, global_step])\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    start_time = time.time()\n",
    "                    if step % 10 == 0:\n",
    "                        tf.logging.info(\n",
    "                            'step: %d,  total Loss %f, secs/step: %f,%s' % (step, loss_t, elapsed_time, time.asctime()))\n",
    "                    \"\"\"checkpoint\"\"\"\n",
    "                    if step % 50 == 0:\n",
    "                        tf.logging.info('saving check point...')\n",
    "                        saver.save(sess, os.path.join(training_path, FLAGS.naming + '.ckpt'), global_step=step)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                saver.save(sess, os.path.join(training_path, 'beiou.ckpt-done'))\n",
    "                tf.logging.info('Done training -- epoch limit reached')\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "                tf.logging.info('coordinator stop')\n",
    "            coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    args = parse_args()\n",
    "    FLAGS = utils.read_conf_file(args.conf)\n",
    "    main(FLAGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
